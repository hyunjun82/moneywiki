#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì •ë¶€ ì‚¬ì´íŠ¸ì—ì„œ ë¯¼ì›ì„œì‹ HWP/PDF ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

ëŒ€ìƒ ì‚¬ì´íŠ¸:
1. ë²•ì œì²˜ êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° (law.go.kr) - ë²•ë ¹ ë³„ì§€ ì„œì‹
2. ì •ë¶€24 (gov.kr) - ë¯¼ì› ì„œì‹
3. êµ­ì„¸ì²­ (nts.go.kr) - ì„¸ê¸ˆ ê´€ë ¨ ì„œì‹
4. ê³ ìš©ë…¸ë™ë¶€ (moel.go.kr) - ê·¼ë¡œê³„ì•½ì„œ ë“±

ì‚¬ìš©ë²•:
    python download-gov-forms.py                    # ì „ì²´ ë‹¤ìš´ë¡œë“œ
    python download-gov-forms.py --form íì—…ì‹ ê³ ì„œ   # íŠ¹ì • ì–‘ì‹ë§Œ
    python download-gov-forms.py --list             # ë‹¤ìš´ ê°€ëŠ¥ ëª©ë¡ í™•ì¸
"""

import os
import sys
import json
import time
import re
import argparse
from pathlib import Path
from urllib.parse import urljoin, quote, unquote

import requests
from bs4 import BeautifulSoup

# ============================================================
# ì„¤ì •
# ============================================================
PROJECT_ROOT = Path(__file__).parent.parent
FORMS_DIR = PROJECT_ROOT / "public" / "files" / "forms"
DATA_DIR = PROJECT_ROOT / "data" / "forms"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
}

# ì–‘ì‹ë³„ ë‹¤ìš´ë¡œë“œ URL ë§¤í•‘
# í˜•ì‹: "ì–‘ì‹ëª…": {"source": "ì¶œì²˜", "url": "ë‹¤ìš´ë¡œë“œURL", "type": "hwp|pdf|xls"}
FORM_SOURCES = {
    # ============ êµ­ì„¸ì²­ (nts.go.kr) ============
    "íì—…ì‹ ê³ ì„œ": {
        "source": "êµ­ì„¸ì²­",
        "sourceUrl": "https://www.nts.go.kr",
        "search_keyword": "íì—…ì‹ ê³ ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },
    "ì‚¬ì—…ìë“±ë¡ì‹ ì²­ì„œ": {
        "source": "êµ­ì„¸ì²­",
        "sourceUrl": "https://www.nts.go.kr",
        "search_keyword": "ì‚¬ì—…ìë“±ë¡ì‹ ì²­ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },
    "íœ´ì—…ì‹ ê³ ì„œ": {
        "source": "êµ­ì„¸ì²­",
        "sourceUrl": "https://www.nts.go.kr",
        "search_keyword": "íœ´ì—…ì‹ ê³ ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },

    # ============ ë²•ì œì²˜ (law.go.kr) ============
    "í˜¼ì¸ì‹ ê³ ì„œ": {
        "source": "ë²•ì œì²˜",
        "sourceUrl": "https://www.law.go.kr",
        "law_name": "ê°€ì¡±ê´€ê³„ì˜ ë“±ë¡ ë“±ì— ê´€í•œ ê·œì¹™",
        "attachment_name": "í˜¼ì¸ì‹ ê³ ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },
    "ì¶œìƒì‹ ê³ ì„œ": {
        "source": "ë²•ì œì²˜",
        "sourceUrl": "https://www.law.go.kr",
        "law_name": "ê°€ì¡±ê´€ê³„ì˜ ë“±ë¡ ë“±ì— ê´€í•œ ê·œì¹™",
        "attachment_name": "ì¶œìƒì‹ ê³ ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },
    "ì‚¬ë§ì‹ ê³ ì„œ": {
        "source": "ë²•ì œì²˜",
        "sourceUrl": "https://www.law.go.kr",
        "law_name": "ê°€ì¡±ê´€ê³„ì˜ ë“±ë¡ ë“±ì— ê´€í•œ ê·œì¹™",
        "attachment_name": "ì‚¬ë§ì‹ ê³ ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },
    "ì´í˜¼ì‹ ê³ ì„œ": {
        "source": "ë²•ì œì²˜",
        "sourceUrl": "https://www.law.go.kr",
        "law_name": "ê°€ì¡±ê´€ê³„ì˜ ë“±ë¡ ë“±ì— ê´€í•œ ê·œì¹™",
        "attachment_name": "ì´í˜¼ì‹ ê³ ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },
    "ì „ì…ì‹ ê³ ì„œ": {
        "source": "ë²•ì œì²˜",
        "sourceUrl": "https://www.law.go.kr",
        "law_name": "ì£¼ë¯¼ë“±ë¡ë²• ì‹œí–‰ê·œì¹™",
        "attachment_name": "ì „ì…ì‹ ê³ ì„œ",
        "category": "ë¯¼ì›Â·í–‰ì •",
    },

    # ============ ê³ ìš©ë…¸ë™ë¶€ (moel.go.kr) ============
    "í•´ê³ ì˜ˆê³ í†µì§€ì„œ": {
        "source": "ê³ ìš©ë…¸ë™ë¶€",
        "sourceUrl": "https://www.moel.go.kr",
        "search_keyword": "í•´ê³ ì˜ˆê³ í†µì§€ì„œ",
        "category": "ê³ ìš©Â·ê·¼ë¡œ",
    },
    "í•´ê³ í†µì§€ì„œ": {
        "source": "ê³ ìš©ë…¸ë™ë¶€",
        "sourceUrl": "https://www.moel.go.kr",
        "search_keyword": "í•´ê³ í†µì§€ì„œ",
        "category": "ê³ ìš©Â·ê·¼ë¡œ",
    },

    # ============ ëŒ€ë²•ì› (scourt.go.kr) ============
    "ì†Œì¥-ë¯¼ì‚¬": {
        "source": "ëŒ€ë²•ì›",
        "sourceUrl": "https://www.scourt.go.kr",
        "search_keyword": "ì†Œì¥",
        "category": "ë²•ë¥ Â·ì†Œì†¡",
    },
    "ì§€ê¸‰ëª…ë ¹ì‹ ì²­ì„œ": {
        "source": "ëŒ€ë²•ì›",
        "sourceUrl": "https://www.scourt.go.kr",
        "search_keyword": "ì§€ê¸‰ëª…ë ¹ì‹ ì²­ì„œ",
        "category": "ë²•ë¥ Â·ì†Œì†¡",
    },
    "í•­ê³ ì¥": {
        "source": "ëŒ€ë²•ì›",
        "sourceUrl": "https://www.scourt.go.kr",
        "search_keyword": "í•­ê³ ì¥",
        "category": "ë²•ë¥ Â·ì†Œì†¡",
    },
}


# ============================================================
# ë²•ì œì²˜ í¬ë¡¤ëŸ¬
# ============================================================
def search_law_forms(law_name, attachment_name):
    """
    ë²•ì œì²˜ì—ì„œ ë²•ë ¹ ë³„ì§€ ì„œì‹ ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ URL ì¶”ì¶œ
    """
    print(f"  ğŸ” ë²•ì œì²˜ ê²€ìƒ‰: {law_name} - {attachment_name}")

    # 1. ë²•ë ¹ ê²€ìƒ‰
    search_url = f"https://www.law.go.kr/ë²•ë ¹/{quote(law_name)}"

    try:
        response = requests.get(search_url, headers=HEADERS, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'lxml')

        # ë³„ì§€ ì„œì‹ ë§í¬ ì°¾ê¸°
        # ë²•ì œì²˜ëŠ” ë³„ì§€ ì„œì‹ì„ ë³„ë„ í˜ì´ì§€ë¡œ ì œê³µ
        attachment_links = soup.select('a[href*="ë³„ì§€"]') or soup.select('a[href*="ì„œì‹"]')

        for link in attachment_links:
            if attachment_name in link.get_text():
                href = link.get('href')
                if href:
                    download_url = urljoin("https://www.law.go.kr", href)
                    return download_url

        # ì§ì ‘ ì„œì‹ í˜ì´ì§€ ì ‘ê·¼ ì‹œë„
        form_url = f"https://www.law.go.kr/ë²•ë ¹ì„œì‹/{quote(law_name)}"
        response = requests.get(form_url, headers=HEADERS, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'lxml')

        # HWP ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
        download_links = soup.select('a[href*=".hwp"]') or soup.select('a[href*="download"]')
        for link in download_links:
            if attachment_name in link.get_text() or attachment_name in str(link):
                return urljoin("https://www.law.go.kr", link.get('href'))

    except Exception as e:
        print(f"    âŒ ë²•ì œì²˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    return None


# ============================================================
# êµ­ì„¸ì²­ í¬ë¡¤ëŸ¬
# ============================================================
def search_nts_forms(keyword):
    """
    êµ­ì„¸ì²­ì—ì„œ ì„œì‹ ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ URL ì¶”ì¶œ
    """
    print(f"  ğŸ” êµ­ì„¸ì²­ ê²€ìƒ‰: {keyword}")

    # êµ­ì„¸ì²­ ì„œì‹ ê²€ìƒ‰ í˜ì´ì§€
    search_url = f"https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=2272&cntntsId=7693"

    try:
        response = requests.get(search_url, headers=HEADERS, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'lxml')

        # ì„œì‹ ëª©ë¡ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
        links = soup.select('a')
        for link in links:
            text = link.get_text(strip=True)
            if keyword in text:
                href = link.get('href')
                if href and ('.hwp' in href or 'download' in href):
                    return urljoin("https://www.nts.go.kr", href)

        # í™ˆíƒìŠ¤ ì„œì‹ ê²€ìƒ‰ ì‹œë„
        hometax_url = f"https://www.hometax.go.kr/websquare/websquare.html?w2xPath=/ui/pp/index_pp.xml"
        # í™ˆíƒìŠ¤ëŠ” JavaScript ê¸°ë°˜ì´ë¼ ì§ì ‘ í¬ë¡¤ë§ ì–´ë ¤ì›€

    except Exception as e:
        print(f"    âŒ êµ­ì„¸ì²­ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    return None


# ============================================================
# ê³ ìš©ë…¸ë™ë¶€ í¬ë¡¤ëŸ¬
# ============================================================
def search_moel_forms(keyword):
    """
    ê³ ìš©ë…¸ë™ë¶€ì—ì„œ ì„œì‹ ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ URL ì¶”ì¶œ
    """
    print(f"  ğŸ” ê³ ìš©ë…¸ë™ë¶€ ê²€ìƒ‰: {keyword}")

    # ê³ ìš©ë…¸ë™ë¶€ ì •ì±…ìë£Œì‹¤
    search_url = f"https://www.moel.go.kr/policy/policydata/list.do"

    try:
        params = {
            'searchText': keyword,
            'searchKeyword': keyword,
        }
        response = requests.get(search_url, headers=HEADERS, params=params, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'lxml')

        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
        links = soup.select('a[href*="download"]') or soup.select('a[href*=".hwp"]')
        for link in links:
            if keyword in link.get_text() or keyword in str(link.get('title', '')):
                return urljoin("https://www.moel.go.kr", link.get('href'))

    except Exception as e:
        print(f"    âŒ ê³ ìš©ë…¸ë™ë¶€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    return None


# ============================================================
# ëŒ€ë²•ì› í¬ë¡¤ëŸ¬
# ============================================================
def search_scourt_forms(keyword):
    """
    ëŒ€ë²•ì›ì—ì„œ ì†Œì†¡ ì„œì‹ ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ URL ì¶”ì¶œ
    """
    print(f"  ğŸ” ëŒ€ë²•ì› ê²€ìƒ‰: {keyword}")

    # ëŒ€ë²•ì› ì „ìì†Œì†¡ ì„œì‹ í˜ì´ì§€
    search_url = "https://ecfs.scourt.go.kr/ecf/ecf300/ECF302.jsp"

    try:
        response = requests.get(search_url, headers=HEADERS, timeout=30)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'lxml')

        # ì„œì‹ ëª©ë¡ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
        links = soup.select('a')
        for link in links:
            text = link.get_text(strip=True)
            if keyword in text:
                href = link.get('href')
                if href:
                    return urljoin("https://ecfs.scourt.go.kr", href)

    except Exception as e:
        print(f"    âŒ ëŒ€ë²•ì› ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    return None


# ============================================================
# íŒŒì¼ ë‹¤ìš´ë¡œë“œ
# ============================================================
def download_file(url, save_path):
    """
    URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    """
    try:
        response = requests.get(url, headers=HEADERS, timeout=60, stream=True)
        response.raise_for_status()

        # Content-Dispositionì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
        content_disp = response.headers.get('Content-Disposition', '')
        if 'filename=' in content_disp:
            # ì¸ì½”ë”©ëœ íŒŒì¼ëª… ì²˜ë¦¬
            match = re.search(r'filename[*]?=(?:UTF-8\'\')?([^;\s]+)', content_disp)
            if match:
                filename = unquote(match.group(1))

        os.makedirs(os.path.dirname(save_path), exist_ok=True)

        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        print(f"    âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {save_path}")
        return True

    except Exception as e:
        print(f"    âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


# ============================================================
# ë©”ì¸ ë¡œì§
# ============================================================
def find_download_url(form_name, form_info):
    """
    ì–‘ì‹ë³„ ë‹¤ìš´ë¡œë“œ URL ì°¾ê¸°
    """
    source = form_info.get('source', '')

    if source == "ë²•ì œì²˜":
        return search_law_forms(
            form_info.get('law_name', ''),
            form_info.get('attachment_name', form_name)
        )
    elif source == "êµ­ì„¸ì²­":
        return search_nts_forms(form_info.get('search_keyword', form_name))
    elif source == "ê³ ìš©ë…¸ë™ë¶€":
        return search_moel_forms(form_info.get('search_keyword', form_name))
    elif source == "ëŒ€ë²•ì›":
        return search_scourt_forms(form_info.get('search_keyword', form_name))

    return None


def process_form(form_name):
    """
    ë‹¨ì¼ ì–‘ì‹ ì²˜ë¦¬
    """
    if form_name not in FORM_SOURCES:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì–‘ì‹: {form_name}")
        print(f"   ì‚¬ìš© ê°€ëŠ¥: {', '.join(FORM_SOURCES.keys())}")
        return False

    form_info = FORM_SOURCES[form_name]
    print(f"\nğŸ“„ {form_name} ì²˜ë¦¬ ì¤‘...")

    # ë‹¤ìš´ë¡œë“œ URL ì°¾ê¸°
    download_url = find_download_url(form_name, form_info)

    if download_url:
        print(f"    ğŸ”— ë‹¤ìš´ë¡œë“œ URL: {download_url}")

        # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
        ext = 'hwp'
        if '.pdf' in download_url.lower():
            ext = 'pdf'
        elif '.doc' in download_url.lower():
            ext = 'docx'
        elif '.xls' in download_url.lower():
            ext = 'xlsx'

        save_path = FORMS_DIR / f"{form_name}.{ext}"

        if download_file(download_url, str(save_path)):
            # JSON íŒŒì¼ ì—…ë°ì´íŠ¸
            update_form_json(form_name, form_info, ext)
            return True
    else:
        print(f"    âš ï¸ ë‹¤ìš´ë¡œë“œ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print(f"    ğŸ’¡ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í•„ìš”: {form_info.get('sourceUrl', '')}")

    return False


def update_form_json(form_name, form_info, ext):
    """
    ì–‘ì‹ JSON íŒŒì¼ì— ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì¶”ê°€
    """
    json_path = DATA_DIR / f"{form_name}.json"

    if json_path.exists():
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    else:
        print(f"    âš ï¸ JSON íŒŒì¼ ì—†ìŒ: {json_path}")
        return

    # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì—…ë°ì´íŠ¸
    if 'downloads' not in data or not data['downloads']:
        data['downloads'] = {}
    if 'downloadNames' not in data or not data['downloadNames']:
        data['downloadNames'] = {}

    data['downloads'][ext] = f"/files/forms/{form_name}.{ext}"
    data['downloadNames'][ext] = f"{form_name}_{form_info['source']}.{ext}"
    data['source'] = form_info['source']
    data['sourceUrl'] = form_info['sourceUrl']

    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"    ğŸ“ JSON ì—…ë°ì´íŠ¸: {json_path}")


def list_available_forms():
    """
    ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ì–‘ì‹ ëª©ë¡ ì¶œë ¥
    """
    print("\nğŸ“‹ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ì–‘ì‹ ëª©ë¡")
    print("=" * 60)

    by_source = {}
    for form_name, info in FORM_SOURCES.items():
        source = info['source']
        if source not in by_source:
            by_source[source] = []
        by_source[source].append(form_name)

    for source, forms in by_source.items():
        print(f"\nğŸ›ï¸ {source}")
        for form in forms:
            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í™•ì¸
            exists = any((FORMS_DIR / f"{form}.{ext}").exists() for ext in ['hwp', 'pdf', 'docx'])
            status = "âœ…" if exists else "â¬œ"
            print(f"   {status} {form}")

    print("\n" + "=" * 60)
    total = len(FORM_SOURCES)
    downloaded = sum(1 for f in FORM_SOURCES if any((FORMS_DIR / f"{f}.{e}").exists() for e in ['hwp', 'pdf', 'docx']))
    print(f"ì´ {total}ê°œ ì¤‘ {downloaded}ê°œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")


def main():
    parser = argparse.ArgumentParser(description='ì •ë¶€ ì‚¬ì´íŠ¸ ì–‘ì‹ ë‹¤ìš´ë¡œë”')
    parser.add_argument('--form', '-f', help='íŠ¹ì • ì–‘ì‹ë§Œ ë‹¤ìš´ë¡œë“œ')
    parser.add_argument('--list', '-l', action='store_true', help='ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥ ëª©ë¡')
    parser.add_argument('--all', '-a', action='store_true', help='ì „ì²´ ë‹¤ìš´ë¡œë“œ')

    args = parser.parse_args()

    if args.list:
        list_available_forms()
        return

    if args.form:
        process_form(args.form)
        return

    if args.all:
        print("ğŸš€ ì „ì²´ ì–‘ì‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        success = 0
        fail = 0

        for form_name in FORM_SOURCES:
            if process_form(form_name):
                success += 1
            else:
                fail += 1
            time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

        print(f"\nğŸ“Š ê²°ê³¼: ì„±ê³µ {success}ê°œ, ì‹¤íŒ¨ {fail}ê°œ")
        return

    # ê¸°ë³¸: ëª©ë¡ ì¶œë ¥
    list_available_forms()
    print("\nì‚¬ìš©ë²•:")
    print("  python download-gov-forms.py --list       # ëª©ë¡ í™•ì¸")
    print("  python download-gov-forms.py --form íì—…ì‹ ê³ ì„œ  # íŠ¹ì • ì–‘ì‹")
    print("  python download-gov-forms.py --all        # ì „ì²´ ë‹¤ìš´ë¡œë“œ")


if __name__ == "__main__":
    main()
