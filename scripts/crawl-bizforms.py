#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë¹„ì¦ˆí¼/ì˜ˆìŠ¤í¼ ì–‘ì‹ í‚¤ì›Œë“œ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ê²°ê³¼: data/form-keywords.csv
"""

import requests
from bs4 import BeautifulSoup
import csv
import time
import os
from datetime import datetime

# ê²°ê³¼ ì €ìž¥ ê²½ë¡œ
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), '..', 'data')
OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'form-keywords.csv')

# ìš”ì²­ í—¤ë”
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
}

# ë¹„ì¦ˆí¼ ì¹´í…Œê³ ë¦¬ URL ëª©ë¡
BIZFORMS_CATEGORIES = [
    # ë¬¸ì„œ/ì„œì‹
    ("íšŒì‚¬ì„œì‹", "https://www.bizforms.co.kr/forml/10/list_1.asp"),
    ("ê²½ë¦¬ì„œì‹", "https://www.bizforms.co.kr/forml/10/200/list_1.asp"),
    ("ì„¸ë¬´íšŒê³„", "https://www.bizforms.co.kr/forml/8/list_1.asp"),
    ("ì¸ì‚¬ì„œì‹", "https://www.bizforms.co.kr/forml/10/218/list_1.asp"),
    ("ë¯¼ì›í–‰ì •", "https://www.bizforms.co.kr/forml/4/list_1.asp"),
    ("ë²•ë¥ ì„œì‹", "https://www.bizforms.co.kr/forml/5/list_1.asp"),
    ("êµìœ¡ì„œì‹", "https://www.bizforms.co.kr/forml/2/list_1.asp"),
    ("ê±´ì„¤ì„œì‹", "https://www.bizforms.co.kr/forml/1/list_1.asp"),
    ("ìƒí™œì„œì‹", "https://www.bizforms.co.kr/forml/7/list_1.asp"),
    ("ê¸ˆìœµì„œì‹", "https://www.bizforms.co.kr/forml/3/list_1.asp"),
    ("ì˜ë¬¸ì„œì‹", "https://www.bizforms.co.kr/forml/9/list_1.asp"),

    # ê³„ì•½ì„œ
    ("ê³„ì•½ì„œ-ê±´ì„¤/ê³µì‚¬", "https://contract.bizforms.co.kr/sample/index.asp?c=148"),
    ("ê³„ì•½ì„œ-ê·¼ë¡œ/ê³ ìš©", "https://contract.bizforms.co.kr/sample/index.asp?c=149"),
    ("ê³„ì•½ì„œ-ê¸ˆì „ê±°ëž˜", "https://contract.bizforms.co.kr/sample/index.asp?c=150"),
    ("ê³„ì•½ì„œ-ë¬¼í’ˆ/ë‚©í’ˆ", "https://contract.bizforms.co.kr/sample/index.asp?c=151"),
    ("ê³„ì•½ì„œ-ë¶€ë™ì‚°", "https://contract.bizforms.co.kr/sample/index.asp?c=152"),
    ("ê³„ì•½ì„œ-ì‚¬ì—…/ë™ì—…", "https://contract.bizforms.co.kr/sample/index.asp?c=153"),
    ("ê³„ì•½ì„œ-ì§€ì‹ìž¬ì‚°", "https://contract.bizforms.co.kr/sample/index.asp?c=155"),
    ("ê³„ì•½ì„œ-íšŒì‚¬ìš´ì˜", "https://contract.bizforms.co.kr/sample/index.asp?c=156"),

    # í‘œì¤€ì„œì‹
    ("í‘œì¤€-ê¸°ì—…ì¼ë°˜", "https://standard.bizforms.co.kr/forml/28/list_1.asp"),
    ("í‘œì¤€-ì¸ì‚¬ê´€ë¦¬", "https://standard.bizforms.co.kr/forml/29st_1.asp"),
    ("í‘œì¤€-ê²½ë¦¬", "https://standard.bizforms.co.kr/forml/30/list_1.asp"),
    ("í‘œì¤€-ê²½ì˜", "https://standard.bizforms.co.kr/forml/31/list_1.asp"),
    ("í‘œì¤€-ì‚¬ê·œê·œì •", "https://standard.bizforms.co.kr/forml/32/list_1.asp"),
    ("í‘œì¤€-ì´ë¬´", "https://standard.bizforms.co.kr/forml/34/list_1.asp"),
    ("í‘œì¤€-ì˜ì—…", "https://standard.bizforms.co.kr/forml/36/list_1.asp"),

    # ìƒ˜í”Œì„œì‹
    ("ìƒ˜í”Œ-ê¸°ì—…ì¼ë°˜", "https://www.bizforms.co.kr/samplel/11/list_1.asp"),
    ("ìƒ˜í”Œ-ê¸°íšì œì•ˆ", "https://www.bizforms.co.kr/samplel/13/list_1.asp"),
    ("ìƒ˜í”Œ-ë²•ë¥ ", "https://www.bizforms.co.kr/samplel/14/list_1.asp"),
    ("ìƒ˜í”Œ-ìƒí™œê°€ì •", "https://www.bizforms.co.kr/samplel/16/list_1.asp"),
    ("ìƒ˜í”Œ-ê³„ì•½ì„œì‹", "https://www.bizforms.co.kr/samplel/27/list_1.asp"),
    ("ìƒ˜í”Œ-ì·¨ì—…ì„œì‹", "https://www.bizforms.co.kr/samplel/96/list_1.asp"),

    # ë¶€ì„œë³„
    ("ë¶€ì„œ-ê²½ë¦¬ë¶€", "https://part.bizforms.co.kr/list.asp?partn=5"),
    ("ë¶€ì„œ-ì¸ì‚¬ë¶€", "https://part.bizforms.co.kr/list.asp?partn=2"),
    ("ë¶€ì„œ-ì´ë¬´ë¶€", "https://part.bizforms.co.kr/list.asp?partn=11"),
    ("ë¶€ì„œ-ê±´ì„¤ë¶€", "https://part.bizforms.co.kr/list.asp?partn=1"),
    ("ë¶€ì„œ-ì˜ì—…ë¶€", "https://part.bizforms.co.kr/list.asp?partn=8"),
    ("ë¶€ì„œ-ê¸°íšë¹„ì„œ", "https://part.bizforms.co.kr/list.asp?partn=12"),

    # ì·¨ì—…ì„œì‹
    ("ì·¨ì—…-ì´ë ¥ì„œ", "https://resume.bizforms.co.kr/resume-form.asp"),
    ("ì·¨ì—…-ìžê¸°ì†Œê°œì„œ", "https://resume.bizforms.co.kr/sector-self-introduction.asp"),
    ("ì·¨ì—…-ê²½ë ¥ê¸°ìˆ ì„œ", "https://resume.bizforms.co.kr/statement-of-career.asp"),
]

def get_page(url, retry=3):
    """íŽ˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸°"""
    for i in range(retry):
        try:
            response = requests.get(url, headers=HEADERS, timeout=10)
            # ì¸ì½”ë”© ìžë™ ê°ì§€ ë˜ëŠ” EUC-KR ì‹œë„
            if 'charset' in response.headers.get('Content-Type', ''):
                response.encoding = response.apparent_encoding
            else:
                # EUC-KR ë¨¼ì € ì‹œë„, ì‹¤íŒ¨í•˜ë©´ UTF-8
                try:
                    response.content.decode('euc-kr')
                    response.encoding = 'euc-kr'
                except:
                    response.encoding = 'utf-8'
            return response.text
        except Exception as e:
            print(f"  ìž¬ì‹œë„ {i+1}/{retry}: {e}")
            time.sleep(2)
    return None

def parse_bizforms_list(html, category):
    """ë¹„ì¦ˆí¼ ëª©ë¡ íŽ˜ì´ì§€ì—ì„œ ì–‘ì‹ëª… ì¶”ì¶œ"""
    keywords = []
    soup = BeautifulSoup(html, 'html.parser')

    # ë‹¤ì–‘í•œ ì„ íƒìž ì‹œë„
    selectors = [
        'a.subject',  # ì¼ë°˜ ëª©ë¡
        'td.subject a',
        'div.subject a',
        'a[href*="form_view"]',
        'a[href*="view.asp"]',
        'li a',
        'td a',
    ]

    for selector in selectors:
        links = soup.select(selector)
        for link in links:
            text = link.get_text(strip=True)
            # í•„í„°ë§: ë¹ˆ í…ìŠ¤íŠ¸, ë©”ë‰´, ë²„íŠ¼ ë“± ì œì™¸
            if text and len(text) > 2 and len(text) < 100:
                if not any(skip in text for skip in ['ë¡œê·¸ì¸', 'íšŒì›ê°€ìž…', 'ë”ë³´ê¸°', 'ì´ì „', 'ë‹¤ìŒ', 'ê²€ìƒ‰', 'í™ˆ', 'ì¹´í…Œê³ ë¦¬']):
                    keywords.append({
                        'keyword': text,
                        'category': category,
                        'source': 'bizforms'
                    })

    return keywords

def crawl_multiple_pages(base_url, category, max_pages=5):
    """ì—¬ëŸ¬ íŽ˜ì´ì§€ í¬ë¡¤ë§"""
    all_keywords = []

    for page in range(1, max_pages + 1):
        # URL íŽ˜ì´ì§€ ë²ˆí˜¸ ë³€ê²½
        if 'list_1.asp' in base_url:
            url = base_url.replace('list_1.asp', f'list_{page}.asp')
        elif 'page=' in base_url:
            url = base_url.split('page=')[0] + f'page={page}'
        else:
            url = f"{base_url}&page={page}" if '?' in base_url else f"{base_url}?page={page}"

        print(f"    íŽ˜ì´ì§€ {page}: {url}")
        html = get_page(url)

        if html:
            keywords = parse_bizforms_list(html, category)
            if not keywords:
                print(f"    â†’ ë” ì´ìƒ ê²°ê³¼ ì—†ìŒ")
                break
            all_keywords.extend(keywords)
            print(f"    â†’ {len(keywords)}ê°œ ìˆ˜ì§‘")

        time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

    return all_keywords

def remove_duplicates(keywords):
    """ì¤‘ë³µ ì œê±°"""
    seen = set()
    unique = []
    for kw in keywords:
        key = kw['keyword'].lower()
        if key not in seen:
            seen.add(key)
            unique.append(kw)
    return unique

def save_to_csv(keywords, filepath):
    """CSV íŒŒì¼ë¡œ ì €ìž¥"""
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

    with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=['keyword', 'category', 'source'])
        writer.writeheader()
        writer.writerows(keywords)

    print(f"\nâœ… ì €ìž¥ ì™„ë£Œ: {filepath}")
    print(f"   ì´ {len(keywords)}ê°œ í‚¤ì›Œë“œ")

def main():
    print("=" * 60)
    print("ðŸ” ë¹„ì¦ˆí¼ ì–‘ì‹ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì‹œìž‘")
    print(f"   ì‹œìž‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    all_keywords = []

    for category, url in BIZFORMS_CATEGORIES:
        print(f"\nðŸ“ [{category}]")
        keywords = crawl_multiple_pages(url, category, max_pages=3)
        all_keywords.extend(keywords)
        print(f"   ì†Œê³„: {len(keywords)}ê°œ")

    # ì¤‘ë³µ ì œê±°
    unique_keywords = remove_duplicates(all_keywords)
    print(f"\nðŸ“Š ì¤‘ë³µ ì œê±°: {len(all_keywords)} â†’ {len(unique_keywords)}ê°œ")

    # ì €ìž¥
    save_to_csv(unique_keywords, OUTPUT_FILE)

    print("\n" + "=" * 60)
    print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"   íŒŒì¼ ìœ„ì¹˜: {os.path.abspath(OUTPUT_FILE)}")
    print("=" * 60)

if __name__ == "__main__":
    main()
