#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Playwright ë¸Œë¼ìš°ì € ìë™í™”ë¡œ ì–‘ì‹ ë‹¤ìš´ë¡œë“œ

ë°©ì‹:
1. ë„¤ì´ë²„ì—ì„œ "ì–‘ì‹ëª… ì–‘ì‹ hwp site:gov.kr" ê²€ìƒ‰
2. ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ ë°©ë¬¸
3. HWP/PDF ë‹¤ìš´ë¡œë“œ ë§í¬ í´ë¦­
4. íŒŒì¼ ì €ì¥

ì‚¬ìš©ë²•:
    python download-forms-playwright.py ê°ì„œ
    python download-forms-playwright.py --all
    python download-forms-playwright.py --batch 10
"""

import os
import sys
import json
import time
import re
import argparse
import asyncio
from pathlib import Path
from urllib.parse import quote, unquote, urlparse

from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout

# ============================================================
# ì„¤ì •
# ============================================================
PROJECT_ROOT = Path(__file__).parent.parent
FORMS_DIR = PROJECT_ROOT / "public" / "files" / "forms"
DATA_DIR = PROJECT_ROOT / "data" / "forms"

# ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë¶€ê¸°ê´€ ë„ë©”ì¸
TRUSTED_DOMAINS = [
    'gov.kr', 'go.kr',
    'nts.go.kr', 'hometax.go.kr',
    'moel.go.kr', 'law.go.kr', 'scourt.go.kr',
    'gangnam.go.kr', 'seoul.go.kr',
    'sejong.go.kr', 'busan.go.kr',
    'incheon.go.kr', 'daegu.go.kr',
]


# ============================================================
# ì§ì ‘ ì‚¬ì´íŠ¸ ê²€ìƒ‰ (ê°•ë‚¨êµ¬ì²­ ë¯¼ì›ì„œì‹)
# ============================================================
async def search_gangnam_direct(form_name, page):
    """ê°•ë‚¨êµ¬ì²­ ë¯¼ì›ì„œì‹ì—ì„œ ì§ì ‘ ê²€ìƒ‰"""
    print(f"  ğŸ” ê°•ë‚¨êµ¬ì²­ ì§ì ‘ ê²€ìƒ‰...")

    try:
        url = f"https://www.gangnam.go.kr/board/B_000060/list.do?searchKeyword={quote(form_name)}"
        await page.goto(url, timeout=30000)
        await page.wait_for_load_state('networkidle', timeout=10000)

        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì–‘ì‹ ë§í¬ ì°¾ê¸°
        links = await page.query_selector_all('a[href*="view.do"]')

        for link in links:
            text = await link.inner_text() or ''
            if form_name in text:
                href = await link.get_attribute('href')
                if href:
                    # ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™
                    detail_url = f"https://www.gangnam.go.kr{href}" if href.startswith('/') else href
                    await page.goto(detail_url, timeout=30000)
                    await page.wait_for_load_state('networkidle', timeout=10000)

                    # ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                    dl_links = await page.query_selector_all('a[href*="download.do"], a[href*=".hwp"]')

                    for dl in dl_links:
                        dl_text = await dl.inner_text() or ''
                        if '.hwp' in dl_text.lower() or 'ë‹¤ìš´ë¡œë“œ' in dl_text or form_name in dl_text:
                            return dl

        return None

    except Exception as e:
        print(f"    âš ï¸ ê°•ë‚¨êµ¬ì²­ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return None


# ============================================================
# ë„¤ì´ë²„ ê²€ìƒ‰
# ============================================================
async def search_naver(form_name, page):
    """ë„¤ì´ë²„ì—ì„œ ì •ë¶€ ì‚¬ì´íŠ¸ ì–‘ì‹ ê²€ìƒ‰"""
    print(f"  ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰...")

    try:
        query = f"{form_name} ì–‘ì‹ hwp ë‹¤ìš´ë¡œë“œ site:gov.kr"
        url = f"https://search.naver.com/search.naver?query={quote(query)}"

        await page.goto(url, timeout=30000)
        await page.wait_for_load_state('networkidle', timeout=10000)

        # ì •ë¶€ ì‚¬ì´íŠ¸ ë§í¬ ì°¾ê¸°
        all_links = await page.query_selector_all('a[href]')

        gov_links = []
        for link in all_links:
            href = await link.get_attribute('href') or ''
            if any(domain in href for domain in TRUSTED_DOMAINS):
                if href.startswith('http') and 'naver.com' not in href:
                    gov_links.append(href)

        return list(dict.fromkeys(gov_links))[:5]

    except Exception as e:
        print(f"    âš ï¸ ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


# ============================================================
# í˜ì´ì§€ì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„
# ============================================================
async def try_download_from_page(form_name, page, url):
    """í˜ì´ì§€ì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ì•„ì„œ ë‹¤ìš´ë¡œë“œ"""
    try:
        print(f"    ğŸŒ ë°©ë¬¸: {url[:50]}...")
        await page.goto(url, timeout=30000)
        await page.wait_for_load_state('networkidle', timeout=10000)

        # ë‹¤ìš´ë¡œë“œ ë§í¬ í›„ë³´ ì°¾ê¸°
        dl_selectors = [
            f'a:has-text("{form_name}")',
            'a[href*=".hwp"]',
            'a[href*="download"]',
            'a[href*="fileDown"]',
            'a:has-text("ë‹¤ìš´ë¡œë“œ")',
            'a:has-text("ì–‘ì‹")',
            'a:has-text("hwp")',
        ]

        for selector in dl_selectors:
            try:
                links = await page.query_selector_all(selector)
                for link in links:
                    href = await link.get_attribute('href') or ''
                    text = await link.inner_text() or ''

                    # ê´€ë ¨ì„± ì²´í¬
                    is_relevant = (
                        form_name in text or
                        '.hwp' in href.lower() or
                        '.hwp' in text.lower() or
                        ('download' in href.lower() and ('ì–‘ì‹' in text or 'ì„œì‹' in text))
                    )

                    if is_relevant:
                        print(f"    â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œë„: {text[:30]}...")

                        try:
                            async with page.expect_download(timeout=30000) as download_info:
                                await link.click()

                            download = await download_info.value

                            # í™•ì¥ì ê²°ì •
                            suggested_name = download.suggested_filename
                            ext = 'hwp'
                            if '.pdf' in suggested_name.lower():
                                ext = 'pdf'
                            elif '.doc' in suggested_name.lower():
                                ext = 'docx'

                            save_path = FORMS_DIR / f"{form_name}.{ext}"
                            await download.save_as(str(save_path))

                            # ê²€ì¦
                            if save_path.exists() and save_path.stat().st_size > 1000:
                                # HWP íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ ì²´í¬
                                with open(save_path, 'rb') as f:
                                    header = f.read(8)

                                if ext == 'hwp' and not header.startswith(b'\xd0\xcf\x11\xe0'):
                                    print(f"    âš ï¸ ìœ íš¨í•œ HWP ì•„ë‹˜")
                                    save_path.unlink()
                                    continue

                                print(f"    âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {save_path.name} ({save_path.stat().st_size:,} bytes)")
                                return ext

                        except PlaywrightTimeout:
                            pass
                        except Exception as e:
                            pass

            except Exception:
                pass

        return None

    except Exception as e:
        print(f"    âš ï¸ í˜ì´ì§€ ë°©ë¬¸ ì‹¤íŒ¨: {e}")
        return None


# ============================================================
# ë©”ì¸ ë‹¤ìš´ë¡œë“œ ë¡œì§
# ============================================================
async def download_form(form_name, browser):
    """ì–‘ì‹ ë‹¤ìš´ë¡œë“œ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ {form_name}")
    print('='*60)

    # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëëŠ”ì§€ í™•ì¸
    for ext in ['hwp', 'pdf', 'docx']:
        existing = FORMS_DIR / f"{form_name}.{ext}"
        if existing.exists() and existing.stat().st_size > 1000:
            print(f"  âœ… ì´ë¯¸ ì¡´ì¬: {form_name}.{ext}")
            return True

    context = await browser.new_context(
        accept_downloads=True,
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    )
    page = await context.new_page()

    try:
        # 1. ê°•ë‚¨êµ¬ì²­ ì§ì ‘ ê²€ìƒ‰
        dl_link = await search_gangnam_direct(form_name, page)
        if dl_link:
            try:
                async with page.expect_download(timeout=30000) as download_info:
                    await dl_link.click()

                download = await download_info.value
                save_path = FORMS_DIR / f"{form_name}.hwp"
                await download.save_as(str(save_path))

                if save_path.exists() and save_path.stat().st_size > 1000:
                    print(f"    âœ… ê°•ë‚¨êµ¬ì²­ì—ì„œ ë‹¤ìš´ë¡œë“œ: {save_path.name}")
                    update_json(form_name, 'hwp')
                    await context.close()
                    return True

            except:
                pass

        # 2. ë„¤ì´ë²„ ê²€ìƒ‰ â†’ ì •ë¶€ ì‚¬ì´íŠ¸ ë°©ë¬¸
        gov_links = await search_naver(form_name, page)

        if gov_links:
            print(f"  ğŸ“„ {len(gov_links)}ê°œ ì •ë¶€ ì‚¬ì´íŠ¸ ë°œê²¬")

            for url in gov_links:
                ext = await try_download_from_page(form_name, page, url)
                if ext:
                    update_json(form_name, ext)
                    await context.close()
                    return True

        print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        await context.close()
        return False

    except Exception as e:
        print(f"  âŒ ì˜¤ë¥˜: {e}")
        await context.close()
        return False


# ============================================================
# JSON ì—…ë°ì´íŠ¸
# ============================================================
def update_json(form_name, ext):
    """ì–‘ì‹ JSON íŒŒì¼ ì—…ë°ì´íŠ¸"""
    json_path = DATA_DIR / f"{form_name}.json"

    if not json_path.exists():
        return

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if 'downloads' not in data or not data['downloads']:
            data['downloads'] = {}
        if 'downloadNames' not in data or not data['downloadNames']:
            data['downloadNames'] = {}

        data['downloads'][ext] = f"/files/forms/{form_name}.{ext}"
        data['downloadNames'][ext] = f"{form_name}.{ext}"

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"    ğŸ“ JSON ì—…ë°ì´íŠ¸ ì™„ë£Œ")

    except Exception as e:
        print(f"    âŒ JSON ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")


# ============================================================
# ë©”ì¸
# ============================================================
def get_missing_forms():
    """ë‹¤ìš´ë¡œë“œ íŒŒì¼ì´ ì—†ëŠ” ì–‘ì‹"""
    missing = []
    for json_file in DATA_DIR.glob('*.json'):
        form_name = json_file.stem
        has_file = any((FORMS_DIR / f"{form_name}.{ext}").exists()
                       for ext in ['hwp', 'pdf', 'docx'])
        if not has_file:
            missing.append(form_name)
    return sorted(missing)


async def main_async(args):
    FORMS_DIR.mkdir(parents=True, exist_ok=True)

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-setuid-sandbox']
        )

        try:
            if args.form_name:
                await download_form(args.form_name, browser)

            elif args.all or args.batch:
                missing = get_missing_forms()
                limit = args.batch if args.batch else len(missing)

                print(f"\nğŸš€ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {min(limit, len(missing))}ê°œ")

                success = 0
                fail = 0

                for form in missing[:limit]:
                    if await download_form(form, browser):
                        success += 1
                    else:
                        fail += 1

                    await asyncio.sleep(2)

                print(f"\n{'='*60}")
                print(f"ğŸ“Š ê²°ê³¼: ì„±ê³µ {success}ê°œ, ì‹¤íŒ¨ {fail}ê°œ")

            elif args.list:
                missing = get_missing_forms()
                downloaded = list(FORMS_DIR.glob('*.hwp')) + list(FORMS_DIR.glob('*.pdf'))
                print(f"\nğŸ“Š í˜„í™©: ë‹¤ìš´ë¡œë“œ {len(downloaded)}ê°œ / ë¯¸ë‹¤ìš´ë¡œë“œ {len(missing)}ê°œ")
                print(f"\në¯¸ë‹¤ìš´ë¡œë“œ ëª©ë¡ (ìƒìœ„ 20ê°œ):")
                for f in missing[:20]:
                    print(f"  â¬œ {f}")

        finally:
            await browser.close()


def main():
    parser = argparse.ArgumentParser(description='Playwright ì–‘ì‹ ë‹¤ìš´ë¡œë”')
    parser.add_argument('form_name', nargs='?', help='ì–‘ì‹ëª…')
    parser.add_argument('--all', '-a', action='store_true', help='ì „ì²´ ë‹¤ìš´ë¡œë“œ')
    parser.add_argument('--batch', '-b', type=int, help='Nê°œë§Œ ë‹¤ìš´ë¡œë“œ')
    parser.add_argument('--list', '-l', action='store_true', help='ëª©ë¡ í™•ì¸')

    args = parser.parse_args()

    if not any([args.form_name, args.all, args.batch, args.list]):
        print("\nì‚¬ìš©ë²•:")
        print("  python download-forms-playwright.py ê°ì„œ           # íŠ¹ì • ì–‘ì‹")
        print("  python download-forms-playwright.py --batch 10    # 10ê°œ ë‹¤ìš´ë¡œë“œ")
        print("  python download-forms-playwright.py --all         # ì „ì²´ ë‹¤ìš´ë¡œë“œ")
        print("  python download-forms-playwright.py --list        # ëª©ë¡ í™•ì¸")
        return

    asyncio.run(main_async(args))


if __name__ == "__main__":
    main()
